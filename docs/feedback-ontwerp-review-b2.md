Feedback for Ontwerp review - blok 2
Note: The activities evaluation will be applied to all members of this group.
Rubric Name: Fixed Leerdoelen Ontwerp review
A1
Je doet onderzoek om het probleem en oplossingsrichtingen in de context in kaart te brengen, herformuleert het vraagstuk, weegt en toetst de belangen van de opdrachtgever, eindgebruiker en andere belanghebbenden. 

Criterion Feedback: Op niveau
I expected to have something about making the list of actions in the summary, but that is not part of your proposition, right?

Fine value proposition.
When it comes to happy flow, the ideal situation is where we integrate the AI process (or multiple ones). But you are focusing on the UI. It would be more interesting to see what is the difference between the UI and AI (think about swimline showing that). From the happy flow, It would have been clear what are the different AI processes, that I see later in the level of automations.

A2
Je stelt voor een AI-oplossing juridische, ethische, organisatorische, functionele en technische requirements op. 

Criterion Feedback: Op niveau
List of requirements is fine, with explanation. Think about including sources of all requirements?
The tables 1 and 2 are so confusing, see how you can document them better (tables should not be crossing pages like this).
And why you have table 2 at this level? Can you combine the 2 tables?
Will table 1 used later to evaluate against the requirements? 

+ Ik zie een aantal goede juridische (privacy) en ethische requirements opgesteld. Fijn dat er ook een bron bij staat, een stakeholder bij staat en een toelichting aan is gekoppeld.


+/- Ik twijfel een beetje over ER05, in principe zou alles wat in de samenvatting staat juridisch bindend moeten zijn, aangezien het gecontroleerd is door de medewerker. Het lijkt me toch best riskant als je ervan uitgaat dat er juridische informatie niet kloppend kan zijn. Hoe zien jullie dit?
+/- Let op het verschil tussen richtlijnen, bv. die van de Rijksoverheid en wetgeving. Ik zou de eerste dan eerder onder ethische requirements stellen, terwijl wetgeving eerder past bij juridische requirements.

A3
Je ontwerpt en verfijnt de kwaliteit van het ontwerp door AI-specifieke ontwerprichtlijnen toe te passen en daarbij te kijken naar aspecten zoals vertrouwen, veiligheid, privacy, elegante foutafhandeling (waaronder edge cases), feedback en controlemechanismen.

Criterion Feedback: Hier is nog werk nodig
You had an AI breakdown in the wiki.
The error flow (in wiki) should show how you handle errors, with focus on the AI processes. In the error flow you showed all possible errors, AI or not. What if you focus on couple of AI errors and focus on how it is handled. This is fine as you focus on errors of generation of summary. Other errors like selection of the type of letter, or empty document, are more non AI relevant errors.
Both should show how you handle errors.

You have a bigger focus on UI/UX, and the UI component you update in each iterations. How are you considereing aspects such as such as trust, security, privacy?

A4
Je onderbouwt in hoeverre AI geschikt is voor een gegeven vraagstuk en maakt een weloverwogen keuze welke mate van automatisering daarbij gewenst is, gelet op technische, maatschappelijke en ethische aspecten. 

Criterion Feedback: Op niveau
It is not clear how AI TL;DR compares to non-AI solutions (manual checklist, static templates).

The level of automations: you identified 7 steps, which are not the processed you need to look at their level of automation or think of the AI breakdown relevant to it. Those are more user actions on the inteface. 
A process can be something like (examples not exactly what you have): annomize, summarize letter,  create action list... Think about what the AI is supposed to do. 
You have the AI breakdown in the wiki, but if follow some of those steps you identified. 
The rationale behind the choice of the levels is not clear. 

+ In de introductie en achtergrondsectie goed beschreven wat het huidige probleem is, en wat de bestaande oplossingen zijn en hoe jullie oplossing zich daar tegenover verhoudt. Mooi om te zien dat jullie het belang van de incorrectheid van informatie heel zwaar wegen in jullie beslissing om voor encoder-decoder modellen te kiezen.
+ De sectie over overwegingen voor het inzetten van AI is duidelijk. Goed dat jullie wat uitzoomen en de vraag stellen in hoeverre AI verantwoord kan worden en daar ook duidelijke keuzes in maken in de voorgestelde oplossing.

C1
Je evalueert hoe de ontwikkelde oplossing werkt en welke (ongewenste) consequenties de AI-oplossing kan hebben voor individu en maatschappij en treedt hierover in gesprek met vakgenoten. 

Criterion Feedback: Op niveau
+- Goed dat jullie laten zien welke requirements wel en niet behaald zijn. Mooi om te kijken of jullie je in de tweede iteratie ook op de nog niet behaalde requirements kunnen richten. Vooral ER04 lijkt me goed om op de te focussen, hoe ga je dit evalueren? En misschien goed om je bewust te zijn van dat er ook nog een grote groep is voor wie B1 nog steeds lastig is.

+- Verder een mooie slotdiscussie en ethische verantwoording. Goed om in de eindversie nog een kort stuk toe te voegen over de verwachte impact van een dergelijke oplossing. Bijv. een paar zinnen op de impact voor de medewerker, de organisatie en de samenleving in zijn geheel, dat kan bijv. door de kosten en baten met elkaar af te wegen.



C3
Je test samen met stakeholders je oplossing met behulp van een prototype in de werkelijke context, en neemt de inzichten mee in je iteratieve proces. 

Criterion Feedback: Op niveau
Ok, showing the tests done, the purpose and the changes based on that in the different iterations 